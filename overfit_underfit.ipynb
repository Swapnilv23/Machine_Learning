{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home work \n",
    "\n",
    "1) make note on overfit \n",
    "\n",
    "2) make note on underfit \n",
    "\n",
    "3) explain bull eye diagram \n",
    "\n",
    "4) understand cross fold and explain it with example (fish.csv ,boston.csv)\n",
    "\n",
    "5) what is bias variance trad off explain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) make note on overfit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Overfitting is a modeling error that occurs when a function is too closely fit to a limited set of data points. Overfitting the model generally takes the form of making an overly complex model to explain idiosyncrasies in the data under study\n",
    "Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model. The problem is that these concepts do not apply to new data and negatively impact the models ability to generalize.\n",
    "\n",
    "Overfitting is more likely with nonparametric and nonlinear models that have more flexibility when learning a target function. As such, many nonparametric machine learning algorithms also include parameters or techniques to limit and constrain how much detail the model learns.\n",
    "\n",
    "For example, decision trees are a nonparametric machine learning algorithm that is very flexible and is subject to overfitting training data. This problem can be addressed by pruning a tree after it has learned in order to remove some of the detail it has picked up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) make note on underfit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Underfitting refers to a model that can neither model the training data nor generalize to new data.\n",
    "\n",
    "An underfit machine learning model is not a suitable model and will be obvious as it will have poor performance on the training data.\n",
    "\n",
    "Underfitting is often not discussed as it is easy to detect given a good performance metric. The remedy is to move on and try alternate machine learning algorithms. Nevertheless, it does provide a good contrast to the problem of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) explain bull eye diagram"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A bull's eye diagram is a simple tool that enables teams to clarify priorities before making a decision. As the name suggests, the diagram is set up to look like a bull's eye."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What is a bull’s eye diagram\n",
    "A bull’s eye diagram is a simple tool that enables teams to clarify priorities before making a decision. As the name suggests, the diagram is set up to look like a bull’s eye. The innermost circle contains the highest priority items, the middle circle contains medium-priority items, and the largest circle contains the lowest priority items.\n",
    "\n",
    "The beauty of the bull’s eye diagram is that it eliminates any possibility for gridlock. Teams struggle to make decisions and build momentum when every task on your list seems like it should be your highest priority. Overwhelmed by tasks, the team fails to move forward. But the bull’s eye diagram solves this problem simply by design. Once you slot high-priority items into the smallest circle, this forces you to shift lesser priorities around, and it becomes impossible to overwhelm your team with a long list of high-priority items.\n",
    "\n",
    "When to use a bull’s eye diagram\n",
    "Use a bull’s eye diagram any time you need to establish priorities, make critical decisions, or talk through a process and remove obstacles with your team. Gridlock occurs when teams struggle to make big decisions. Bull’s eye diagrams empower your team to break down a broader decision into smaller ones, slotting tasks into the diagram according to their level of importance.\n",
    "\n",
    "Create your own bull’s eye diagram\n",
    "Listing tasks on a whiteboard allows your team to quickly move around information related to new tasks added to the bull’s eye. Once you prioritize the tasks in the diagram, you can organize and rearrange as needed. The diagram enables your team to see relationships and categories, and reprioritize, too. The bull’s eye is an easily understood diagram that helps you clarify project priorities.\n",
    "\n",
    "Making your own bull’s eye diagrams is easy. Miro’s whiteboard tool is the perfect canvas to create and share them. Get started by selecting the Bull’s Eye Diagram Template, then take the following steps to make one of your own.\n",
    "\n",
    "Establish a goal. Before you start filling out the diagram, your team should align on a goal. Are you trying to make a decision? Overcoming a challenge? Articulate your goal before ironing out priorities.\n",
    "\n",
    "Make a list of tasks. Think about all the tasks you’ll need to accomplish to achieve your goal. Don’t worry about putting them in any particular order. Timeline and prioritization are irrelevant at this stage. Just focus on getting the lists of tasks on paper. If you’re working through the bull’s eye diagram with your team, it’s helpful to give each team member a few minutes to make their own list. Then you can come together to consolidate the tasks into a master list.\n",
    "\n",
    "Fill in the largest circle. If you start by trying to make decisions about high-priority tasks, you might get stuck. Instead, focus on the lower-stakes items first by filling out the largest part of the circle. Refer back to your list of tasks. Are any of them unnecessary to complete your goal? Are there any “nice-to-haves” instead of “need-to-haves”? Give each team member a few minutes to think through the low-priority items before discussing as a group.\n",
    "\n",
    "Fill in the middle circle. Next, think about medium-priority tasks. These items don’t need to be done immediately, but they are important for achieving your goal. The middle-priority circle is a bit smaller than the low-priority circle, which makes it more challenging to narrow down your tasks. Discuss with your teammates and come to a consensus. \n",
    "\n",
    "Fill in the smallest circle. Now it’s time to figure out your mission-critical priorities. Since this is the smallest circle, you can only fit a few priorities in there. Refer back to your list of tasks. Think about high-priority tasks as necessary conditions. In other words, tasks you must accomplish in order to complete the project. Which two or three tasks are vital to your project? Talk it over with your team members, then complete your tasks and achieve your goal!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) what is bias variance trad off explain"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bias Error\n",
    "Bias are the simplifying assumptions made by a model to make the target function easier to learn.\n",
    "\n",
    "Generally, linear algorithms have a high bias making them fast to learn and easier to understand but generally less flexible. In turn, they have lower predictive performance on complex problems that fail to meet the simplifying assumptions of the algorithms bias.\n",
    "\n",
    "Low Bias: Suggests less assumptions about the form of the target function.\n",
    "High-Bias: Suggests more assumptions about the form of the target function.\n",
    "Examples of low-bias machine learning algorithms include: Decision Trees, k-Nearest Neighbors and Support Vector Machines.\n",
    "\n",
    "Examples of high-bias machine learning algorithms include: Linear Regression, Linear Discriminant Analysis and Logistic Regression.\n",
    "\n",
    "Variance Error\n",
    "Variance is the amount that the estimate of the target function will change if different training data was used.\n",
    "\n",
    "The target function is estimated from the training data by a machine learning algorithm, so we should expect the algorithm to have some variance. Ideally, it should not change too much from one training dataset to the next, meaning that the algorithm is good at picking out the hidden underlying mapping between the inputs and the output variables.\n",
    "\n",
    "Machine learning algorithms that have a high variance are strongly influenced by the specifics of the training data. This means that the specifics of the training have influences the number and types of parameters used to characterize the mapping function.\n",
    "\n",
    "Low Variance: Suggests small changes to the estimate of the target function with changes to the training dataset.\n",
    "High Variance: Suggests large changes to the estimate of the target function with changes to the training dataset.\n",
    "Generally, nonlinear machine learning algorithms that have a lot of flexibility have a high variance. For example, decision trees have a high variance, that is even higher if the trees are not pruned before use.\n",
    "\n",
    "Examples of low-variance machine learning algorithms include: Linear Regression, Linear Discriminant Analysis and Logistic Regression.\n",
    "\n",
    "Examples of high-variance machine learning algorithms include: Decision Trees, k-Nearest Neighbors and Support Vector Machines.\n",
    "\n",
    "Bias-Variance Trade-Off\n",
    "The goal of any supervised machine learning algorithm is to achieve low bias and low variance. In turn the algorithm should achieve good prediction performance.\n",
    "\n",
    "You can see a general trend in the examples above:\n",
    "\n",
    "Linear machine learning algorithms often have a high bias but a low variance.\n",
    "Nonlinear machine learning algorithms often have a low bias but a high variance.\n",
    "The parameterization of machine learning algorithms is often a battle to balance out bias and variance.\n",
    "\n",
    "Below are two examples of configuring the bias-variance trade-off for specific algorithms:\n",
    "\n",
    "The k-nearest neighbors algorithm has low bias and high variance, but the trade-off can be changed by increasing the value of k which increases the number of neighbors that contribute t the prediction and in turn increases the bias of the model.\n",
    "The support vector machine algorithm has low bias and high variance, but the trade-off can be changed by increasing the C parameter that influences the number of violations of the margin allowed in the training data which increases the bias but decreases the variance.\n",
    "There is no escaping the relationship between bias and variance in machine learning.\n",
    "\n",
    "Increasing the bias will decrease the variance.\n",
    "Increasing the variance will decrease the bias.\n",
    "There is a trade-off at play between these two concerns and the algorithms you choose and the way you choose to configure them are finding different balances in this trade-off for your problem\n",
    "\n",
    "In reality, we cannot calculate the real bias and variance error terms because we do not know the actual underlying target function. Nevertheless, as a framework, bias and variance provide the tools to understand the behavior of machine learning algorithms in the pursuit of predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
